{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2be5065",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#La-métrique-d'évaluation\" data-toc-modified-id=\"La-métrique-d'évaluation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>La métrique d'évaluation</a></span></li></ul></li><li><span><a href=\"#Chargement-des-ressources\" data-toc-modified-id=\"Chargement-des-ressources-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Chargement des ressources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-du-workspace\" data-toc-modified-id=\"Chargement-du-workspace-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Chargement du workspace</a></span></li></ul></li><li><span><a href=\"#Développement-des-modèles\" data-toc-modified-id=\"Développement-des-modèles-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Développement des modèles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modèle-baseline\" data-toc-modified-id=\"Modèle-baseline-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Modèle baseline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recherche-des-hyperparamètres\" data-toc-modified-id=\"Recherche-des-hyperparamètres-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Recherche des hyperparamètres</a></span></li><li><span><a href=\"#Analyse-des-résultats\" data-toc-modified-id=\"Analyse-des-résultats-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Analyse des résultats</a></span></li><li><span><a href=\"#Enregistrement-des-hyperparamètres\" data-toc-modified-id=\"Enregistrement-des-hyperparamètres-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Enregistrement des hyperparamètres</a></span></li></ul></li><li><span><a href=\"#Modèle-de-type-content-based\" data-toc-modified-id=\"Modèle-de-type-content-based-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Modèle de type content based</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cold-start-problem\" data-toc-modified-id=\"Cold-start-problem-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Cold start problem</a></span></li><li><span><a href=\"#Recherche-des-hyperparamètres\" data-toc-modified-id=\"Recherche-des-hyperparamètres-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Recherche des hyperparamètres</a></span></li><li><span><a href=\"#Analyse-des-résultats\" data-toc-modified-id=\"Analyse-des-résultats-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Analyse des résultats</a></span></li><li><span><a href=\"#Enregistrement-des-hyperparamètres\" data-toc-modified-id=\"Enregistrement-des-hyperparamètres-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Enregistrement des hyperparamètres</a></span></li></ul></li><li><span><a href=\"#Modèle-de-collaborative-filtering\" data-toc-modified-id=\"Modèle-de-collaborative-filtering-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Modèle de collaborative filtering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cold-start-problem\" data-toc-modified-id=\"Cold-start-problem-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Cold start problem</a></span></li><li><span><a href=\"#Recherche-des-hyperparamètres\" data-toc-modified-id=\"Recherche-des-hyperparamètres-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Recherche des hyperparamètres</a></span></li><li><span><a href=\"#Analyse-des-résultats\" data-toc-modified-id=\"Analyse-des-résultats-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Analyse des résultats</a></span></li><li><span><a href=\"#Enregistrement-des-hyperparamètres\" data-toc-modified-id=\"Enregistrement-des-hyperparamètres-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Enregistrement des hyperparamètres</a></span></li></ul></li></ul></li><li><span><a href=\"#Sélection-du-meilleur-modèle\" data-toc-modified-id=\"Sélection-du-meilleur-modèle-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sélection du meilleur modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparaison-des-résultats\" data-toc-modified-id=\"Comparaison-des-résultats-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Comparaison des résultats</a></span></li><li><span><a href=\"#Enregistrement-du-modèle\" data-toc-modified-id=\"Enregistrement-du-modèle-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Enregistrement du modèle</a></span></li></ul></li><li><span><a href=\"#Analyse-du-modèle\" data-toc-modified-id=\"Analyse-du-modèle-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analyse du modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-du-modèle\" data-toc-modified-id=\"Chargement-du-modèle-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Chargement du modèle</a></span></li><li><span><a href=\"#Chargement-des-données-de-test\" data-toc-modified-id=\"Chargement-des-données-de-test-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Chargement des données de test</a></span></li><li><span><a href=\"#Evaluation-sur-le-jeu-de-test\" data-toc-modified-id=\"Evaluation-sur-le-jeu-de-test-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Evaluation sur le jeu de test</a></span></li></ul></li><li><span><a href=\"#Déploiement-manuel-du-MVP\" data-toc-modified-id=\"Déploiement-manuel-du-MVP-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Déploiement manuel du MVP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Déploiement-du-modèle-sur-Azure-Container-Instances\" data-toc-modified-id=\"Déploiement-du-modèle-sur-Azure-Container-Instances-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Déploiement du modèle sur Azure Container Instances</a></span></li><li><span><a href=\"#Test-du-modèle\" data-toc-modified-id=\"Test-du-modèle-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Test du modèle</a></span></li><li><span><a href=\"#Déploiement-du-service-de-prédiction\" data-toc-modified-id=\"Déploiement-du-service-de-prédiction-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Déploiement du service de prédiction</a></span></li><li><span><a href=\"#Test-du-service-de-prédiction\" data-toc-modified-id=\"Test-du-service-de-prédiction-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Test du service de prédiction</a></span></li><li><span><a href=\"#Nettoyage-des-ressources\" data-toc-modified-id=\"Nettoyage-des-ressources-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Nettoyage des ressources</a></span></li></ul></li><li><span><a href=\"#Architecture-de-déploiement-automatisé\" data-toc-modified-id=\"Architecture-de-déploiement-automatisé-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Architecture de déploiement automatisé</a></span></li><li><span><a href=\"#Pour-aller-plus-loin\" data-toc-modified-id=\"Pour-aller-plus-loin-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Pour aller plus loin</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cdf066",
   "metadata": {
    "gather": {
     "logged": 1635146389029
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from P9_02_scripts.datasets import *\n",
    "from P9_02_scripts.models import *\n",
    "from notebook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935a848",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce notebook fait suite au précédent notebook `modélisation.ipynb`. Nous commencerons par tester et évaluer différents modèles de recommandation. Nous allons ensuite les comparer et sélectionner le plus performant. Enfin nous déployerons notre système de recommandation.\n",
    "\n",
    "Le but de ce projet est de créer au plus vite un MVP qui pourra être présenté à l'équipe et à des utilisteurs. Nous n'allons donc pas rechercher le modèle de recommandation le plus performant.\n",
    "\n",
    "Nous nous sommes plutôt concentré sur la création et l'implémentation de notre architecture MLOps qui nous a permit d'obtenir rapidement une première version du MVP. Nous pourrons ainsi rapidement itérer sur de futurs versions. De plus, la distribution des données du dataset que nous utilisons ici peut être très différente de celle que nous aurons dans la réalité (articles différents etc...). Cela a été un argument de plus pour nous concentrer sur la mise en place de notre architecture qui nous permettra de rapidement expérimenter et déployer des modèles avec nos futures données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0294ee70",
   "metadata": {},
   "source": [
    "## La métrique d'évaluation\n",
    "\n",
    "Notre système de recommandation a pour but de présenter du contenus pertinents à nos utilisateurs. La question est de savoir comment mesurer l'efficacité de ce système.\n",
    "\n",
    "Il existe plusieurs types de métriques ([en savoir plus](https://github.com/microsoft/recommenders/tree/main/examples/03_evaluate)). Parmis elles, on retrouve :\n",
    "- `Rating metrics` : Nous allons mesurer la performance du système à prédire les notations des articles (RMSE etc...). Ces métriques sont intrasèques aux modèle et ne sont donc pas adaptés à tous les modèles. De plus, elles sont plus difficilement interprétables car elle ne dépendent pas directement de la pertinance des recommandations faites à l'utilisateur.\n",
    "- `Ranking metrics` : Permettent de mesurer la pertinance des recommandations pour les utilisateurs (precision, recall etc...). Ces métriques sont des mesure extrinsèques et peuvent être adaptées à tous les modèles. Elle sont facilement interprétables mais peuvent être très couteuse en ressources.\n",
    "- `Business metrics` : Les précédentes métriques pourraient pousser un modèle à recommander des articles dit \"pièges à clicks\" et qui ont par exemple des titres très accrocheurs. Cela pourrait faire baisser notre taux de rétention ainsi que le temps passé par les utilisateurs sur notre site. On peux alors utiliser des métriques comme le temps moyen passé par un utilisateur sur notre site et chercher ainsi à l'améliorer.\n",
    "\n",
    "Les `Business metrics` semblent être les plus intéressantes de notre point de vue. Il nous semble cependant un peu tôt pour en sélectionner une, surtout dans le cadre de ce MVP. Nous allons donc prendre une `Ranking metrics` inspirée du kernel Kaggle suivant : [Recommender Systems in Python 101](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101#Evaluation). Il s'agit de la métrique `Recall@5` qui va mesurer la proportion de contenu pertinent sur 5 recommandations effectuées parmis un échantillon de 101 articles.\n",
    "\n",
    "Voici son algorithme :\n",
    "- Pour chaque article cliqué par un utilisateur :\n",
    "\t- On crée une liste de 100 articles jamais cliqués par cet utilisateur (vrais négatifs).\n",
    "\t- On ajoute l’article cliqué par l’utilisateur dans la liste.\n",
    "\t- On demande au modèle de prédire 5 recommandations parmi ces 101 articles.\n",
    "\t- `user_article_recall` = l’article est dans les 5 recommandations.\n",
    "- `Recall@5` = moyenne de tous `les user_article_recall`.\n",
    "\n",
    "Cette algorithme est un bon compromis entre rapidité d'évaluation et interprétabilité. En effet, la partie la plus gourmande en ressources est la création des listes de 100 articles jamais cliqués par les utilisateurs (vrais négatifs). Or cette partie à déjà été réalisée lors de l'ajout de vrais négatifs dans les jeux de notations des articles créés dans le pipeline de transformation des données.\n",
    "\n",
    "Dans une première version de cet algorithme, nous avons échantillonné 100 articles parmis tous ceux disponibles dans le jeu de données. Dans cette version, on obtenait des scores `Recall@5` proches de 1 simplement en sélectionnant les 5 articles les plus récents. Il s'agissait donc d'un algorithme trop naïf et facilement contournable. L'astuce a été d'échantillonner 100 articles parmis ceux qui ont récemment été cliqués par d'autres utilisateurs et qui ont donc récemment suscité un intérêt. Cela a permis de rendre l'algorithme de calcul du `Recall@5` beaucoup plus robuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7c95f",
   "metadata": {},
   "source": [
    "# Chargement des ressources\n",
    "\n",
    "Nous allons charger les ressources Azure qui vont nous permettre d'exécuter nos scripts d'entrainement sur des clusters de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ec754",
   "metadata": {},
   "source": [
    "## Chargement du workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6fece",
   "metadata": {
    "gather": {
     "logged": 1635146405042
    }
   },
   "outputs": [],
   "source": [
    "# On charge l’espace de travail Azure Machine Learning existant\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d257416",
   "metadata": {},
   "source": [
    "# Développement des modèles\n",
    "\n",
    "Nous allons ici développer et expérimenter divers modèles de recommandation :\n",
    "\n",
    "<img src=\"./data/img/archi_dev.png\" alt=\"Développement et expérimentation\" style=\"width:800px;\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Développement et expérimentation</p>\n",
    "\n",
    "Dans le précédent notebook, nous avons réalisé les blocs `Data analysis` et `Data transform`. Dans cette section, nous allons voir les blocs `Model training` et `Model evaluation`. Nous allons itérer ces opérations sur divers modèles en recherchant les meilleurs hyperparamètres. Nous allons ensuite sauvegarder les scripts d'entrainement ainsi que les meilleur hyperparamètres de chaque modèle dans notre repository Github."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0eca3c0",
   "metadata": {},
   "source": [
    "## Modèle baseline\n",
    "\n",
    "Nous allons commencer par tester 3 modèles naïfs qui vont nous servir de base de comparaison avec les autres modèles :\n",
    "1. Recommande les 5 articles les plus récents.\n",
    "2. Recommande les 5 articles les plus populaires (ceux qui ont le plus de clicks).\n",
    "3. Recommande 5 articles au hasard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288d037",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres\n",
    "\n",
    "Ces 3 types de recommandation sont implémentés en tant qu'hyperparamètre dans la classe `BaselineRecommender`. Nous allons les tester et ne conserver que la meilleure version pour notre baseline.\n",
    "\n",
    "Nous allons tester toutes les combinaisons de manière exhaustive en utilisant une recherche par grille. L'entrainement et l'évaluation du modèle étant très rapides, nous n'allons pas utiliser de stratégie d'arrêt anticipée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ca0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Jeux de données\n",
    "    \"train_user_article_ratings\": \"train_user_article_ratings\",\n",
    "    \"valid_user_article_ratings\": \"valid_user_article_ratings\",\n",
    "    \"article_profiles\": \"article_profiles\",\n",
    "    \n",
    "    # Hyperparamètres\n",
    "    \"rating_col\": DEFAULT_RATING_COL\n",
    "}\n",
    "\n",
    "gs_params = {\n",
    "    \"baseline_type\": [\"most_recent\", \"most_popular\", \"random\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a03890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P9_02_scripts.model_baseline_train.run import exp_submit\n",
    "\n",
    "# On lance la recherche des hyperparamètres\n",
    "run = exp_submit(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"model_baseline_train\",\n",
    "    params,\n",
    "    gs_params=gs_params,\n",
    "    wait_for_completion=False,\n",
    "    show_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec38233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On affiche un widget avec les détails de l'exécution\n",
    "# RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106199d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On attend la fin de l'exécution\n",
    "run.wait_for_completion(show_output=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dbc54",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f553ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la dernière exécution de l'expérience.\n",
    "run = get_last_run(ws, \"model_baseline_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la meilleure exécution de la recherche des hyperparamètres.\n",
    "best_run = run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les hyperparamètres du meilleur modèle\n",
    "best_hyperparameters = json.loads(run.get_hyperparameters()[best_run.id])\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e61abf",
   "metadata": {},
   "source": [
    "On obtient le meilleur Recall@5 en recommandant 5 articles au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6776c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On télécharge le fichier contenant les résultats de l'évaluation du modèle\n",
    "best_run.download_file(\"outputs/res.parquet\", PARQUET_PATH + \"model_baseline_train_res.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf60307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ouvre et on affiche les résultats\n",
    "res = pd.read_parquet(PARQUET_PATH + \"model_baseline_train_res.parquet\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6cf50",
   "metadata": {},
   "source": [
    "On obtient un Recall@5 très faible de 0.049 sur le jeu de validation.\n",
    "\n",
    "Sur toutes les recommandations faites aux utilisateurs, notre système n'a fait que 4.9% de recommandations pertinantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa077b9",
   "metadata": {},
   "source": [
    "### Enregistrement des hyperparamètres\n",
    "\n",
    "Nous allons enregistrer les meilleurs hyperparamètres dans le fichier `params.json` du dossier contenant les scripts d'entrainement du modèle. Ce fichier sera sauvegardé dans le repository Github et pourra être utilisé lors du déploiement automatisé du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met en forme les paramètres\n",
    "best_hyperparameters = {k.replace(\"--\", \"\"): v for k, v in best_hyperparameters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour les paramètres de base avec les meilleurs hyperparameters\n",
    "params.update(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les paramètres\n",
    "with open(\"../P9_02_scripts/model_baseline_train/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68505d64",
   "metadata": {},
   "source": [
    "## Modèle de type content based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f60b21",
   "metadata": {},
   "source": [
    "### Cold start problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1fc05d",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Jeux de données\n",
    "    \"train_user_article_ratings\": \"train_user_article_ratings\",\n",
    "    \"valid_user_article_ratings\": \"valid_user_article_ratings\",\n",
    "    \"article_profiles\": \"article_profiles\",\n",
    "    \"train_user_profiles\": \"train_user_profiles\",\n",
    "    \n",
    "    # Hyperparamètres\n",
    "    \"rating_col\": DEFAULT_RATING_COL\n",
    "}\n",
    "\n",
    "gs_params = {\n",
    "    \"num_vars_scale\": [0., 0.5, 1.],\n",
    "    \"cat_vars_scale\": [0., 0.5, 1.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P9_02_scripts.model_content_based_train.run import exp_submit\n",
    "\n",
    "# On lance la recherche des hyperparamètres\n",
    "run = exp_submit(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"model_content_based_train\",\n",
    "    params,\n",
    "    gs_params=gs_params,\n",
    "    wait_for_completion=False,\n",
    "    show_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fba58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On affiche un widget avec les détails de l'exécution\n",
    "# RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e15996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On attend la fin de l'exécution\n",
    "run.wait_for_completion(show_output=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c1e3f9",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4fda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la dernière exécution de l'expérience.\n",
    "run = get_last_run(ws, \"model_content_based_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la meilleure exécution de la recherche des hyperparamètres.\n",
    "best_run = run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0479ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les hyperparamètres du meilleur modèle\n",
    "best_hyperparameters = json.loads(run.get_hyperparameters()[best_run.id])\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a83866",
   "metadata": {},
   "source": [
    "On obtient le meilleur Recall@5 en utilisant les embeddings ainsi que les catégories des articles dans la recherche de contenus pertinents pour l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74992751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On télécharge le fichier contenant les résultats de l'évaluation du modèle\n",
    "best_run.download_file(\"outputs/res.parquet\", PARQUET_PATH + \"model_content_based_train_res.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ouvre et on affiche les résultats\n",
    "res = pd.read_parquet(PARQUET_PATH + \"model_content_based_train_res.parquet\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5a5f0",
   "metadata": {},
   "source": [
    "On obtient un Recall@5 de 0.172 sur le jeu de validation.\n",
    "\n",
    "Sur toutes les recommandations faites aux utilisateurs, notre système a fait 17% de recommandations pertinantes. Ce score est bien meilleur que celui de notre baseline !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9f406",
   "metadata": {},
   "source": [
    "### Enregistrement des hyperparamètres\n",
    "\n",
    "Nous allons enregistrer les meilleurs hyperparamètres dans le fichier `params.json` du dossier contenant les scripts d'entrainement du modèle. Ce fichier sera sauvegardé dans le repository Github et pourra être utilisé lors du déploiement automatisé du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met en forme les paramètres\n",
    "best_hyperparameters = {k.replace(\"--\", \"\"): v for k, v in best_hyperparameters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour les paramètres de base avec les meilleurs hyperparameters\n",
    "params.update(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les paramètres\n",
    "with open(\"../P9_02_scripts/model_content_based_train/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d970a48",
   "metadata": {},
   "source": [
    "## Modèle de collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd88bcc",
   "metadata": {},
   "source": [
    "### Cold start problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010676ec",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Jeux de données\n",
    "    \"train_user_article_ratings\": \"train_user_article_ratings\",\n",
    "    \"valid_user_article_ratings\": \"valid_user_article_ratings\",\n",
    "    \"article_profiles\": \"article_profiles\"\n",
    "}\n",
    "\n",
    "gs_params = {\n",
    "    \"rating_col\": [\"rating_click_nb\", \"rating_click_per_session_ratio\"],\n",
    "    \"n_factors\": [50, 100, 200],\n",
    "    \"n_epochs\": [10, 20, 30],\n",
    "    \"lr_all\": [0.0001, 0.005, 0.025],\n",
    "    \"reg_all\": [0.004, 0.02, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77be304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P9_02_scripts.model_collaborative_filtering_train.run import exp_submit\n",
    "\n",
    "# On lance la recherche des hyperparamètres\n",
    "run = exp_submit(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"model_collaborative_filtering_train\",\n",
    "    params,\n",
    "    gs_params=gs_params,\n",
    "    wait_for_completion=False,\n",
    "    show_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On affiche un widget avec les détails de l'exécution\n",
    "# RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39285192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On attend la fin de l'exécution\n",
    "run.wait_for_completion(show_output=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61780f71",
   "metadata": {},
   "source": [
    "### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la dernière exécution de l'expérience.\n",
    "run = get_last_run(ws, \"model_collaborative_filtering_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la meilleure exécution de la recherche des hyperparamètres.\n",
    "best_run = run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les hyperparamètres du meilleur modèle\n",
    "best_hyperparameters = json.loads(run.get_hyperparameters()[best_run.id])\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On télécharge le fichier contenant les résultats de l'évaluation du modèle\n",
    "best_run.download_file(\"outputs/res.parquet\", PARQUET_PATH + \"model_collaborative_filtering_train_res.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ouvre et on affiche les résultats\n",
    "res = pd.read_parquet(PARQUET_PATH + \"model_collaborative_filtering_train_res.parquet\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93656999",
   "metadata": {},
   "source": [
    "On obtient un Recall@5 très faible de 0.049 sur le jeu de validation.\n",
    "\n",
    "Sur toutes les recommandations faites aux utilisateurs, notre système n'a fait que 4.9% de recommandations pertinantes. \n",
    "\n",
    "Ce modèle ne fait donc pas mieux que la baseline. Cela pourrait être du au fait que ce modèle fasses des recommandations trop variées. Les utilisateurs de ce jeu de données sont peut-être plus intéressés par les mêmes types de contenu, ce qui expliquerait les bien meilleurs résultats obtenus avec le modèle de type content based.\n",
    "\n",
    "Une autre hypothèse pourrait être que notre système de notation inplicite des articles n'est pas assez représentatif de la pertinance ou non d'un article du point de vu de l'utilisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fe7b1",
   "metadata": {},
   "source": [
    "### Enregistrement des hyperparamètres\n",
    "\n",
    "Nous allons enregistrer les meilleurs hyperparamètres dans le fichier `params.json` du dossier contenant les scripts d'entrainement du modèle. Ce fichier sera sauvegardé dans le repository Github et pourra être utilisé lors du déploiement automatisé du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab97929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met en forme les paramètres\n",
    "best_hyperparameters = {k.replace(\"--\", \"\"): v for k, v in best_hyperparameters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f96a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour les paramètres de base avec les meilleurs hyperparameters\n",
    "params.update(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les paramètres\n",
    "with open(\"../P9_02_scripts/model_collaborative_filtering_train/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf1f47",
   "metadata": {},
   "source": [
    "# Sélection du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26b977",
   "metadata": {},
   "source": [
    "## Comparaison des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85938785",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline_train_res = pd.read_parquet(PARQUET_PATH + \"model_baseline_train_res.parquet\")\n",
    "model_content_based_train_res = pd.read_parquet(PARQUET_PATH + \"model_content_based_train_res.parquet\")\n",
    "model_collaborative_filtering_train_res = pd.read_parquet(PARQUET_PATH + \"model_collaborative_filtering_train_res.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réunit tous les résultats\n",
    "valid_res = pd.concat([\n",
    "    model_baseline_train_res,\n",
    "    model_content_based_train_res,\n",
    "    model_collaborative_filtering_train_res\n",
    "])\n",
    "\n",
    "# On classe les modèles en fonction du meilleur recall obtenu sur le jeu de validation\n",
    "valid_res = valid_res.sort_values(\"recall@5\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# On modifie le nom des colonnes\n",
    "valid_res = valid_res.rename(columns={\n",
    "    \"precision@5\": \"valid_precision@5\",\n",
    "    \"recall@5\": \"valid_recall@5\",\n",
    "})\n",
    "valid_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5616cc",
   "metadata": {},
   "source": [
    "On obtient le meilleur Recall@5 sur le jeu de validation avec le modèle de type content based."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcdaf7",
   "metadata": {},
   "source": [
    "## Enregistrement du modèle\n",
    "\n",
    "Nous allons enregistrer manuellement notre meilleur modèle afin de pouvoir l'évaluer et le déployer dans ce notebook. En production, cette étape sera réalisée automatiquement après l'entrainement du modèle dans le pipeline de déploiement automatisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd496a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la dernière exécution de l'expérience.\n",
    "run = get_last_run(ws, \"model_content_based_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la meilleure exécution de la recherche des hyperparamètres.\n",
    "best_run = run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre le modèle\n",
    "model = best_run.register_model(\n",
    "    model_name=\"recommender\",\n",
    "    model_path=\"outputs/model.joblib\",\n",
    "    tags={\"class_name\": \"ContentBasedRecommender\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63180c",
   "metadata": {},
   "source": [
    "# Analyse du modèle\n",
    "\n",
    "Avant de déployer notre modèle, nous allons l'évaluer sur le jeu de test afin de vérifier qu'il généralise correctement sur des données qu'il n'a jamais vu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ee12f",
   "metadata": {},
   "source": [
    "## Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640297f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On télécharge les données\n",
    "model = Model(ws, \"recommender\")\n",
    "model_path = model.download(target_dir=MODEL_PATH, exist_ok=True)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d892ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from P9_02_scripts import models\n",
    "\n",
    "# On inscrit les modules nécessaires au chargement du modèle\n",
    "sys.modules['models'] = models\n",
    "\n",
    "# On charge le modèle\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7b121",
   "metadata": {},
   "source": [
    "## Chargement des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40536b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les datasets\n",
    "test_user_article_ratings_ds = Dataset.get_by_name(ws, \"test_user_article_ratings\")\n",
    "article_profiles_ds = Dataset.get_by_name(ws, \"article_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676dcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les datasets dans des DataFrames\n",
    "test_user_article_ratings = test_user_article_ratings_ds.to_pandas_dataframe()\n",
    "article_profiles = article_profiles_ds.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On filtre les colonnes pour obtenir le format : user_id, article_id, rating_id\n",
    "test_ratings = test_user_article_ratings[[\"user_id\", \"article_id\", DEFAULT_RATING_COL]]\n",
    "test_ratings = test_ratings.rename(columns={DEFAULT_RATING_COL: \"rating\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e468a3",
   "metadata": {},
   "source": [
    "## Evaluation sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = get_precision_recall_n_score(\n",
    "    model,\n",
    "    \"ContentBasedRecommender\",\n",
    "    test_ratings,\n",
    "    article_profiles,\n",
    "    top_n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On recomme les colonnes\n",
    "test_res = test_res.rename(columns={\n",
    "    \"precision@5\": \"test_precision@5\",\n",
    "    \"recall@5\": \"test_recall@5\",\n",
    "})\n",
    "\n",
    "# On merge les résultats avec ceux du jeu de validation\n",
    "pd.merge(valid_res, test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae490d",
   "metadata": {},
   "source": [
    "On obtient sur le jeu de test un Recall@5 de 0.193.\n",
    "\n",
    "Ce score est similaire, voir même supérieur à celui obtenu sur le jeu de validation (0.172). Cela semble indiquer que notre modèle généralise correctement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d41d84",
   "metadata": {},
   "source": [
    "# Déploiement manuel du MVP\n",
    "\n",
    "<img src=\"./data/images/MLOps level 0.svg\" alt=\"MLOps level 0.svg\" width=\"900\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">MLOps level 0 (<a href=\"https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\">source</a>)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53f57b",
   "metadata": {},
   "source": [
    "## Déploiement du modèle sur Azure Container Instances\n",
    "\n",
    "Nous allons utiliser Azure Container Instances. Il s'agit d'une solution simple pour déployer un modèle à titre expérimental. Cette solution est cependant déconseillé par Microsoft pour le déploiement de modèle en production.\n",
    "\n",
    "Azure va automatiquement créer un servce web et un point de terminaison pour y accéder via une API REST. Quand le service web recevra des tweets à analyser, il les transmettra à un fichier de scoring que l'on doit lui fournir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P9_02_scripts.model_content_based_deploy_aci.run import model_deploy\n",
    "\n",
    "model_aci = model_deploy(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"model_content_based_deploy_aci\",\n",
    "    show_output=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cf627",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_aci.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c71b77",
   "metadata": {},
   "source": [
    "## Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc87bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"user_id\": \"1234\",\n",
    "    \"session_start_dt\": datetime(2017, 10, 16, 12).isoformat(),\n",
    "    \"top_n\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a193f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(model_aci.scoring_uri, json=data)\n",
    "\n",
    "if not r.ok:\n",
    "    print(f\"Erreur de type {r.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5431ddc",
   "metadata": {},
   "source": [
    "## Déploiement du service de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = SCRIPTS_PATH + \"model_content_based_deploy_aci/.env\"\n",
    "dst = FUNCTION_PATH + \"recommender/.env\"\n",
    "\n",
    "# On crée le fichier .env dans le dossier de l'azure function\n",
    "copy2(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d149687",
   "metadata": {},
   "source": [
    "Création et déploiement de l'azure function :\n",
    "- `conda activate p9`\n",
    "- `cd P9_03_function/`\n",
    "- `./function_create.sh`\n",
    "- `./function_deploy.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a82ad5",
   "metadata": {},
   "source": [
    "## Test du service de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On lit les configurations\n",
    "config_parser = ConfigParser()\n",
    "config_parser.read(FUNCTION_PATH + \"function_config.txt\")\n",
    "\n",
    "# On récupère le nom du site\n",
    "azure_function_name = config_parser.get(\"DEFAULT\", \"functionAppName\").strip('\"')\n",
    "print(f\"Le nom de l'azure function est : {azure_function_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a21eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"userId\": \"1234\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f\"https://{azure_function_name}.azurewebsites.net/api/recommender\", json=data)\n",
    "\n",
    "if not r.ok:\n",
    "    print(f\"Erreur de type {r.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14547cc1",
   "metadata": {},
   "source": [
    "## Nettoyage des ressources\n",
    "\n",
    "On pensera à supprimer le service web à la fin de cette démonstration pour éviter des coût inutiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère le endpoint du modèle déployé\n",
    "model_aci = Webservice(ws, \"p9-recommender-aci\")\n",
    "\n",
    "# On supprime le endpoint\n",
    "model_aci.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25d0ac",
   "metadata": {},
   "source": [
    "Suppression du groupe de ressources du service de prédiction\n",
    "- `conda activate p9`\n",
    "- `cd P9_03_function/`\n",
    "- `./function_delete.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b7c55",
   "metadata": {},
   "source": [
    "# Architecture de déploiement automatisé\n",
    "\n",
    "<img src=\"./data/images/MLOps level 1.svg\" alt=\"MLOps level 1.svg\" width=\"900\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">MLOps level 1 (<a href=\"https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\">source</a>)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc3dbc",
   "metadata": {},
   "source": [
    "# Pour aller plus loin"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "p9"
  },
  "kernelspec": {
   "display_name": "p9",
   "language": "python",
   "name": "p9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Sommaire",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "351px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
