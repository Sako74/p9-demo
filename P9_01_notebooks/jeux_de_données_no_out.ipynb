{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fde5e55",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#MVP\" data-toc-modified-id=\"MVP-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>MVP</a></span></li><li><span><a href=\"#Architecture-MLOps\" data-toc-modified-id=\"Architecture-MLOps-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Architecture MLOps</a></span></li><li><span><a href=\"#Le-jeu-de-données\" data-toc-modified-id=\"Le-jeu-de-données-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Le jeu de données</a></span></li></ul></li><li><span><a href=\"#Chargement-des-ressources\" data-toc-modified-id=\"Chargement-des-ressources-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Chargement des ressources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-du-workspace\" data-toc-modified-id=\"Chargement-du-workspace-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Chargement du workspace</a></span></li><li><span><a href=\"#Chargement-du-magasin-de-données\" data-toc-modified-id=\"Chargement-du-magasin-de-données-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Chargement du magasin de données</a></span></li></ul></li><li><span><a href=\"#Exploration-et-analyse-des-données\" data-toc-modified-id=\"Exploration-et-analyse-des-données-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploration et analyse des données</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fichiers-clicks_hour_xxx.csv\" data-toc-modified-id=\"Fichiers-clicks_hour_xxx.csv-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Fichiers clicks_hour_xxx.csv</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-des-fichiers\" data-toc-modified-id=\"Chargement-des-fichiers-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Chargement des fichiers</a></span></li><li><span><a href=\"#Convertion-des-types\" data-toc-modified-id=\"Convertion-des-types-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Convertion des types</a></span></li><li><span><a href=\"#Longueur-des-sessions\" data-toc-modified-id=\"Longueur-des-sessions-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Longueur des sessions</a></span></li><li><span><a href=\"#Indicateurs-statistiques\" data-toc-modified-id=\"Indicateurs-statistiques-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Indicateurs statistiques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-de-type-numérique\" data-toc-modified-id=\"Variables-de-type-numérique-3.1.4.1\"><span class=\"toc-item-num\">3.1.4.1&nbsp;&nbsp;</span>Variables de type numérique</a></span></li><li><span><a href=\"#Variables-de-type-catégorie\" data-toc-modified-id=\"Variables-de-type-catégorie-3.1.4.2\"><span class=\"toc-item-num\">3.1.4.2&nbsp;&nbsp;</span>Variables de type catégorie</a></span></li></ul></li><li><span><a href=\"#Répartition-des-clicks-par-article\" data-toc-modified-id=\"Répartition-des-clicks-par-article-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Répartition des clicks par article</a></span></li><li><span><a href=\"#Répartition-des-clicks-par-utilisateur\" data-toc-modified-id=\"Répartition-des-clicks-par-utilisateur-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Répartition des clicks par utilisateur</a></span></li><li><span><a href=\"#Répartition-des-clicks-par-jour\" data-toc-modified-id=\"Répartition-des-clicks-par-jour-3.1.7\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Répartition des clicks par jour</a></span></li><li><span><a href=\"#Nombre-d'utilisateurs-par-jour\" data-toc-modified-id=\"Nombre-d'utilisateurs-par-jour-3.1.8\"><span class=\"toc-item-num\">3.1.8&nbsp;&nbsp;</span>Nombre d'utilisateurs par jour</a></span></li></ul></li><li><span><a href=\"#Fichier-articles_metadata.csv\" data-toc-modified-id=\"Fichier-articles_metadata.csv-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Fichier articles_metadata.csv</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convertion-des-types\" data-toc-modified-id=\"Convertion-des-types-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Convertion des types</a></span></li><li><span><a href=\"#Indicateurs-statistiques\" data-toc-modified-id=\"Indicateurs-statistiques-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Indicateurs statistiques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-de-type-numérique\" data-toc-modified-id=\"Variables-de-type-numérique-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span>Variables de type numérique</a></span></li><li><span><a href=\"#Variables-de-type-catégorie\" data-toc-modified-id=\"Variables-de-type-catégorie-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span>Variables de type catégorie</a></span></li></ul></li><li><span><a href=\"#Suppression-des-variables-inutiles\" data-toc-modified-id=\"Suppression-des-variables-inutiles-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Suppression des variables inutiles</a></span></li><li><span><a href=\"#Distribution-du-nombre-d'articles-par-catégorie\" data-toc-modified-id=\"Distribution-du-nombre-d'articles-par-catégorie-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Distribution du nombre d'articles par catégorie</a></span></li><li><span><a href=\"#Nombre-d'articles-ajoutés-par-an\" data-toc-modified-id=\"Nombre-d'articles-ajoutés-par-an-3.2.5\"><span class=\"toc-item-num\">3.2.5&nbsp;&nbsp;</span>Nombre d'articles ajoutés par an</a></span></li></ul></li><li><span><a href=\"#Fichier-articles_embeddings.pickle\" data-toc-modified-id=\"Fichier-articles_embeddings.pickle-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Fichier articles_embeddings.pickle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Indicateurs-statistiques\" data-toc-modified-id=\"Indicateurs-statistiques-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Indicateurs statistiques</a></span></li></ul></li></ul></li><li><span><a href=\"#Enregistrement-des-données-dans-le-feature-store\" data-toc-modified-id=\"Enregistrement-des-données-dans-le-feature-store-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Enregistrement des données dans le feature store</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-des-données\" data-toc-modified-id=\"Chargement-des-données-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Chargement des données</a></span></li><li><span><a href=\"#Enregistrement-dans-le-datastore\" data-toc-modified-id=\"Enregistrement-dans-le-datastore-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Enregistrement dans le datastore</a></span></li><li><span><a href=\"#Enregistrement-des-datasets\" data-toc-modified-id=\"Enregistrement-des-datasets-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Enregistrement des datasets</a></span></li></ul></li><li><span><a href=\"#Pipeline-de-transformation-des-données\" data-toc-modified-id=\"Pipeline-de-transformation-des-données-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pipeline de transformation des données</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extraction-des-données\" data-toc-modified-id=\"Extraction-des-données-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Extraction des données</a></span></li><li><span><a href=\"#Transformation-des-données\" data-toc-modified-id=\"Transformation-des-données-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Transformation des données</a></span><ul class=\"toc-item\"><li><span><a href=\"#Création-des-notation-des-articles\" data-toc-modified-id=\"Création-des-notation-des-articles-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Création des notation des articles</a></span></li><li><span><a href=\"#Création-des-profils-des-articles\" data-toc-modified-id=\"Création-des-profils-des-articles-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Création des profils des articles</a></span></li><li><span><a href=\"#Création-des-profils-des-utilisateurs\" data-toc-modified-id=\"Création-des-profils-des-utilisateurs-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Création des profils des utilisateurs</a></span></li><li><span><a href=\"#Exécution-du-pipeline\" data-toc-modified-id=\"Exécution-du-pipeline-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Exécution du pipeline</a></span></li></ul></li></ul></li><li><span><a href=\"#Vérification-des-données\" data-toc-modified-id=\"Vérification-des-données-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Vérification des données</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chargement-des-datasets\" data-toc-modified-id=\"Chargement-des-datasets-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Chargement des datasets</a></span></li><li><span><a href=\"#Notation-des-articles\" data-toc-modified-id=\"Notation-des-articles-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Notation des articles</a></span></li><li><span><a href=\"#Profils-des-articles\" data-toc-modified-id=\"Profils-des-articles-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Profils des articles</a></span></li><li><span><a href=\"#Profils-des-utilisateurs\" data-toc-modified-id=\"Profils-des-utilisateurs-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Profils des utilisateurs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432e142-126c-49cf-8096-b1a57ebf0aa4",
   "metadata": {
    "gather": {
     "logged": 1635146241144
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from P9_02_scripts.datasets import *\n",
    "from P9_02_scripts.data_transform.run import *\n",
    "from notebook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64eeb8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "La mission de notre entreprise est d'encourager la lecture en recommandant des contenus pertinents à nos utilisateurs.\n",
    "\n",
    "Ce projet a pour but la réalisation d'un MVP d'un système de recommandation de contenu sous la forme d'une application mobile. Le repository Github de ce projet se trouve à l'adresse suivante : [p9-demo](https://github.com/Sako74/p9-demo).\n",
    "\n",
    "<img src=\"./data/gif/mvp_demo_tiny.gif\" alt=\"Démonstration MVP\" style=\"width:200px;\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Démonstration du MVP</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47b2cf",
   "metadata": {},
   "source": [
    "## MVP\n",
    "\n",
    "Fonctions de l'application mobile :\n",
    "- Simulation de l’authentification d’un utilisateur.\n",
    "- Recommandation de 5 articles.\n",
    "\n",
    "Fonctions et contraintes du système de recommandation :\n",
    "- Utilisation des services de Azure.\n",
    "- Stockage des scripts sur Github.\n",
    "- Anticiper l’ajout de nouveaux utilisateurs.\n",
    "- Anticiper l’ajout de nouveaux articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6697a0",
   "metadata": {},
   "source": [
    "## Architecture MLOps\n",
    "\n",
    "Le MLOps est une culture et une pratique d'ingénierie ML qui vise à unifier le développement de systèmes ML et leur mise en opération (Ops). Appliquer le MLOps signifie que l'on vise l'automatisation et la surveillance de toutes les étapes de la construction d'un système de ML, y compris l'intégration, les tests, la publication, le déploiement et la gestion de l'infrastructure ([en savoir plus](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)).\n",
    "\n",
    "Nous avons donc mis en place une architecture MLOps afin de pouvoir itérer rapidement sur les versions de notre MVP.\n",
    "\n",
    "<img src=\"./data/img/archi_mlops.png\" alt=\"Architecture MLOps\" width=\"900\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Architecture MLOps</p>\n",
    "\n",
    "Voici la description du code couleur :\n",
    "- Les blocks en gris sont ceux qui n'ont pas encore été implémentés.\n",
    "- Les blocks en bleu sont ceux qui utilisent des services Azure.\n",
    "- Les blocks en vert sont ceux qui utilisent Github.\n",
    "- Le block en jaune est l'application mobile développée en React par un prestataire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a13aa4",
   "metadata": {},
   "source": [
    "## Le jeu de données\n",
    "\n",
    "Nous allons utiliser un jeu de données fournit gratuitement par [Globo.com](https://www.globo.com/), un site de news brésilien. Ce jeu de données est disponible à l'adresse suivante : [jeu de données](https://www.kaggle.com/gspmoreira/news-portal-user-interactions-by-globocom). Commençons par télécharger nos données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b56471",
   "metadata": {
    "gather": {
     "logged": 1635146167928
    }
   },
   "outputs": [],
   "source": [
    "# Lien vers le dataset\n",
    "DATASET_URL = \"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+9+-+R%C3%A9alisez+une+application+mobile+de+recommandation+de+contenu/news-portal-user-interactions-by-globocom.zip\"\n",
    "\n",
    "# Fichiers du dataset\n",
    "csv_files = [\"articles_metadata.csv\", \"clicks_sample.csv\"]\n",
    "zip_file = \"clicks\"\n",
    "pickle_file = \"articles_embeddings.pickle\"\n",
    "\n",
    "needed_files = csv_files + [zip_file] + [pickle_file]\n",
    "\n",
    "# Fichiers actuellement présents\n",
    "current_files = os.listdir(CSV_PATH)\n",
    "current_files += os.listdir(PICKLE_PATH)\n",
    "\n",
    "# On vérifie si tous les fichiers/dossiers sont bien présents\n",
    "if all([i in current_files for i in needed_files]):\n",
    "    print(\"Tous les fichiers sont bien présents.\")\n",
    "# Sinon on télécharge et on extrait les données\n",
    "else:\n",
    "    print(\"Téléchargement des données en cours...\")\n",
    "\n",
    "    # On télécharge le .zip dans un fichier temporaire et on extrait les données\n",
    "    tmp, _ = urllib.request.urlretrieve(DATASET_URL)\n",
    "    with zipfile.ZipFile(tmp, \"r\") as f:\n",
    "        # On extrait les fichiers csv\n",
    "        for i in csv_files:\n",
    "            f.extract(i, CSV_PATH)\n",
    "        \n",
    "        # On extrait le fichier zip contenant des fichiers csv\n",
    "        with f.open(zip_file + \".zip\") as f2:\n",
    "            with zipfile.ZipFile(f2, \"r\") as f3:\n",
    "                f3.extractall(CSV_PATH)\n",
    "        \n",
    "        # On extrait le fichier pickle\n",
    "        f.extract(pickle_file, PICKLE_PATH)\n",
    "\n",
    "    # On supprime le fichier temporaire\n",
    "    urllib.request.urlcleanup()\n",
    "    \n",
    "    print(\"Téléchargement des données terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef86334",
   "metadata": {},
   "source": [
    "# Chargement des ressources\n",
    "\n",
    "Nous allons charger toutes les ressources Azure qui vont nous permettre de créer et d'enregistrer des jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa680c9",
   "metadata": {},
   "source": [
    "## Chargement du workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae64ec",
   "metadata": {
    "gather": {
     "logged": 1635146257971
    }
   },
   "outputs": [],
   "source": [
    "# On charge l’espace de travail Azure Machine Learning existant\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b94e2",
   "metadata": {},
   "source": [
    "## Chargement du magasin de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c35d2b",
   "metadata": {
    "gather": {
     "logged": 1635146260604
    }
   },
   "outputs": [],
   "source": [
    "# On charge le magasin de données par défaut\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55bb11f",
   "metadata": {},
   "source": [
    "# Exploration et analyse des données\n",
    "\n",
    "Cette partie représente le block `Data analysis` de notre architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e624d5b",
   "metadata": {},
   "source": [
    "## Fichiers clicks_hour_xxx.csv\n",
    "\n",
    "Le jeu de données est composé de fichiers de logs enregistrés heure par heure. Ils contiennent des informations sur les articles cliqués par les utilisateurs ainsi que des informations sur les sessions des utilisateurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cbe77b",
   "metadata": {},
   "source": [
    "### Chargement des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beceec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_dir = CSV_PATH + \"clicks\"\n",
    "\n",
    "# On ouvre les fichiers et on ajoute les données dans une liste\n",
    "clicks = []\n",
    "for i in tqdm(os.listdir(clicks_dir), leave=False):\n",
    "    tmp = pd.read_csv(os.path.join(clicks_dir, i))\n",
    "    clicks.append(tmp)\n",
    "    \n",
    "# On concatène toutes les données\n",
    "clicks = pd.concat(clicks)\n",
    "clicks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e70fd",
   "metadata": {},
   "source": [
    "Nous avons en tout 2.988.181 individus et 12 variables. Voyons un échantillon de ces données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156515f",
   "metadata": {},
   "source": [
    "### Convertion des types\n",
    "\n",
    "Nous allons commencer par convertir les types des variables. Certains types, comme `uint8`, ont été choisis afin d'optimiser la mémoire. Nous les avons sélectionné après avoir observé les indicateurs statistiques de ces variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1704f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour le type des variables\n",
    "clicks = clicks.astype({\n",
    "    \"user_id\": np.uint64,\n",
    "    \"session_id\": np.uint64,\n",
    "    \"session_start\": np.uint64,\n",
    "    \"session_size\": np.uint16,\n",
    "    \"click_article_id\": np.uint64,\n",
    "    \"click_timestamp\": np.uint64,\n",
    "    \"click_environment\": np.uint8,\n",
    "    \"click_deviceGroup\": np.uint8,\n",
    "    \"click_os\": np.uint8,\n",
    "    \"click_country\": np.uint8,\n",
    "    \"click_region\": np.uint8,\n",
    "    \"click_referrer_type\": np.uint8\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On convertit les timestamps en datetime\n",
    "clicks[\"session_start\"] = pd.to_datetime(clicks['session_start'], unit='ms')\n",
    "clicks[\"click_timestamp\"] = pd.to_datetime(clicks['click_timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme les colonnes\n",
    "clicks = clicks.rename(columns={\n",
    "    \"session_start\": \"session_start_dt\",\n",
    "    \"click_timestamp\": \"click_dt\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a12d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On trie par ordre chronologique\n",
    "clicks = clicks.sort_values(\"click_dt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9fa0a",
   "metadata": {},
   "source": [
    "### Longueur des sessions\n",
    "\n",
    "Voyons quelques indicateurs statistiques sur la longueur des sessions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par session\n",
    "grp = clicks.groupby(\"session_id\")\n",
    "\n",
    "# On agrège les données\n",
    "grp_agg = grp.agg({\"session_start_dt\": \"min\", \"click_dt\": \"max\"})\n",
    "\n",
    "# On calcule le timedelta entre le dernier click et le début de la session\n",
    "grp_agg[\"session_length_td\"] = grp_agg[\"click_dt\"] - grp_agg[\"session_start_dt\"]\n",
    "grp_agg[\"session_length_td\"].describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178a570",
   "metadata": {},
   "source": [
    "99% des sessions durent moins de 5h40 et 75% durent moins de 16min.\n",
    "\n",
    "La session la plus longue a duré 28 jours, il s'agit donc d'une valeur atypique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25338d",
   "metadata": {},
   "source": [
    "### Indicateurs statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\n",
    "    \"session_size\",\n",
    "    \"session_start_dt\",\n",
    "    \"click_dt\"\n",
    "]\n",
    "\n",
    "cat_vars = [\n",
    "    \"user_id\",\n",
    "    \"session_id\",\n",
    "    \"click_article_id\",\n",
    "    \"click_environment\",\n",
    "    \"click_deviceGroup\",\n",
    "    \"click_os\",\n",
    "    \"click_country\",\n",
    "    \"click_region\",\n",
    "    \"click_referrer_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf48e1",
   "metadata": {},
   "source": [
    "#### Variables de type numérique\n",
    "\n",
    "Voici le tableau des indicateurs statistiques des variables de type numérique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[num_vars].describe(\n",
    "    percentiles=[0.25, 0.5, 0.75, 0.95, 0.99],\n",
    "    datetime_is_numeric=True\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d1518",
   "metadata": {},
   "source": [
    "En moyenne, les utilisateurs cliquent sur 4 articles par session.\n",
    "\n",
    "99% des clicks ont été effectués avant le 16/10/2017 à 23h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd856a",
   "metadata": {},
   "source": [
    "#### Variables de type catégorie\n",
    "\n",
    "Voici le tableau des indicateurs statistiques des variables de type catégorie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cec9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[cat_vars].astype(\"category\").describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64edeb",
   "metadata": {},
   "source": [
    "Il y a 322.897 utilisateurs différents qui ont cliqués sur 46.033 articles différents.\n",
    "\n",
    "Un des utilisateurs a cliqué sur 1232 articles.\n",
    "\n",
    "Un des articles a été cliqué 37213 fois."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2d408",
   "metadata": {},
   "source": [
    "### Répartition des clicks par article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par article\n",
    "grp = clicks.groupby(\"click_article_id\")\n",
    "\n",
    "# On agrège les données\n",
    "grp_agg = grp.agg({\"click_dt\": \"count\"})\n",
    "grp_agg = grp_agg.rename(columns={\"click_dt\": \"click_nb\"})\n",
    "\n",
    "# On affiche les indicateurs statistiques\n",
    "grp_agg.describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71539510",
   "metadata": {},
   "source": [
    "99% des articles ont été cliqués moins de 1204 fois et 75% moins de 6 fois.\n",
    "\n",
    "L'article qui a été cliqué 37213 fois est une valeur atypique. Il s'agit peut-être d'un article qui a fait le buzz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "grp_agg.plot.hist(bins=50, ax=ax)\n",
    "\n",
    "ax.set_title(\"Distribution des clicks par article\")\n",
    "ax.set_xlabel(\"Nombre de clicks par article\")\n",
    "ax.set_ylabel(\"Effectif (log)\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb61a29",
   "metadata": {},
   "source": [
    "### Répartition des clicks par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f592fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par article\n",
    "grp = clicks.groupby(\"user_id\")\n",
    "\n",
    "# On agrège les données\n",
    "grp_agg = grp.agg({\"click_dt\": \"count\"})\n",
    "grp_agg = grp_agg.rename(columns={\"click_dt\": \"click_nb\"})\n",
    "\n",
    "# On affiche les indicateurs statistiques\n",
    "grp_agg.describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4aa76",
   "metadata": {},
   "source": [
    "99% des articles ont été cliqués moins de 67 fois et 75% moins de 10 fois.\n",
    "\n",
    "L'utilisateur qui a été cliqué 1232 fois est une valeur atypique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ad905",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "grp_agg.plot.hist(bins=50, ax=ax)\n",
    "\n",
    "ax.set_title(\"Distribution des clicks par utilisateur\")\n",
    "ax.set_xlabel(\"Nombre de clicks par utilisateur\")\n",
    "ax.set_ylabel(\"Effectif (log)\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f68aeb",
   "metadata": {},
   "source": [
    "### Répartition des clicks par jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par jour\n",
    "grp = clicks.groupby(pd.Grouper(key=\"click_dt\", freq=\"D\"))\n",
    "\n",
    "# On agrège les données\n",
    "grp_agg = grp.agg({\n",
    "    \"click_dt\": lambda x: x.max() - x.min(),\n",
    "    \"click_article_id\": \"count\"\n",
    "})\n",
    "grp_agg = grp_agg.rename(columns={\n",
    "    \"click_dt\": \"click_delta\",\n",
    "    \"click_article_id\": \"click_nb\",\n",
    "})\n",
    "grp_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596c9cc",
   "metadata": {},
   "source": [
    "On constate qu'à partir du 17/10 il y a beaucoup moins de cliques par jours.\n",
    "\n",
    "Afin de conserver un nombre de cliques par jour conséquent, nous n'allons travailler que sur la période du 01/10 au 16/10 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les jours qui ont trop peu de cliques\n",
    "clicks = clicks[clicks[\"click_dt\"] < datetime(2017, 10, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2953d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "clicks[\"click_dt\"].dt.date.value_counts().sort_index().plot.bar(ax=ax)\n",
    "\n",
    "ax.set_title(\"Nombre de clicks par jour\")\n",
    "ax.set_xlabel(\"Jour\")\n",
    "ax.set_ylabel(\"Nombre de clicks\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10b478",
   "metadata": {},
   "source": [
    "Nous avons au minimum 92.163 cliques dans une journée. Il s'agit d'un nombre conséquent et nous pourrons donc splitter nos données en fonction des jours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b01e39",
   "metadata": {},
   "source": [
    "### Nombre d'utilisateurs par jour\n",
    "\n",
    "Les systèmes de recommandation sont confrontés au cold start problem. Par exemple, quoi recommander à un nouvel utilisateur dont on a que très peu d'information ?\n",
    "\n",
    "Nous allons donc observer l'évolution du nombre de nouveaux utilisateurs jour par jour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par jour\n",
    "grp = clicks.groupby(pd.Grouper(key=\"click_dt\", freq=\"D\"))\n",
    "\n",
    "# On calcule l'ensemble cumulé des ids des utilisateurs par jour\n",
    "grp_agg = grp.agg({\"user_id\": lambda x: x.unique().tolist()}) \n",
    "grp_agg[\"user_id\"] = grp_agg[\"user_id\"].cumsum().apply(set)\n",
    "\n",
    "# On ajoute une colonne représentant le jour précédent\n",
    "grp_agg[\"prev_user_id\"] = grp_agg[\"user_id\"].shift(1)\n",
    "grp_agg[\"prev_user_id\"] = grp_agg[\"prev_user_id\"].fillna(\"\").apply(set)\n",
    "\n",
    "# On calcule le nombre d'utilisateur connus et inconnus par jour\n",
    "grp_agg[\"user_nb\"] = grp_agg[[\"user_id\", \"prev_user_id\"]].aggregate(lambda x: len(x[0] & x[1]), axis=1)\n",
    "grp_agg[\"new_user_nb\"] = (grp_agg[\"user_id\"] - grp_agg[\"prev_user_id\"]).apply(len)\n",
    "\n",
    "# On nettoie les colonnes et l'index pour l'affichage\n",
    "grp_agg = grp_agg[[\"user_nb\", \"new_user_nb\"]]\n",
    "grp_agg[\"%\"] = grp_agg[\"new_user_nb\"] / (grp_agg[\"new_user_nb\"] + grp_agg[\"user_nb\"])\n",
    "grp_agg = grp_agg.rename(columns={\n",
    "    \"user_nb\": \"nombre d'utilisateurs connus dans la journée\",\n",
    "    \"new_user_nb\": \"nombre d'utilisateurs inconnus dans la journée\",\n",
    "    \"%\": \"ratio d'inconnus\",\n",
    "})\n",
    "grp_agg.index = grp_agg.index.date\n",
    "grp_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20b2b1",
   "metadata": {},
   "source": [
    "Le premier jour, tous les utilisateurs sont considérés comme inconnus.\n",
    "\n",
    "Au bout de 5 jours, nous avons déjà moins de 10% d'utilisateurs inconnus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "grp_agg[[\n",
    "    \"nombre d'utilisateurs connus dans la journée\",\n",
    "    \"nombre d'utilisateurs inconnus dans la journée\"\n",
    "]].plot.bar(ax=ax)\n",
    "\n",
    "ax.set_title(\"Nombre d'utilisateurs par jour avec mise à jour quotidienne des nouveaux utilisateurs\")\n",
    "ax.set_xlabel(\"Jour\")\n",
    "ax.set_ylabel(\"Nombre d'utilisateurs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nettoie les ressources\n",
    "del(clicks)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32746b9",
   "metadata": {},
   "source": [
    "## Fichier articles_metadata.csv\n",
    "\n",
    "Ce fichier contient des informations sur les articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ddf850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les métadonnées des articles\n",
    "articles_metadata = pd.read_csv(CSV_PATH + \"articles_metadata.csv\")\n",
    "articles_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca931ae2",
   "metadata": {},
   "source": [
    "Nous avons 364.047 individus et 5 variables. Voyons un échantillon de ces données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f84fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4b06d",
   "metadata": {},
   "source": [
    "### Convertion des types\n",
    "\n",
    "Nous allons commencer par convertir les types des variables. Certains types, comme `uint8`, ont été choisis afin d'optimiser la mémoire. Nous les avons sélectionné après avoir observé les indicateurs statistiques de ces variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour le type des variables\n",
    "articles_metadata = articles_metadata.astype({\n",
    "    \"article_id\": np.uint64,\n",
    "    \"category_id\": np.uint16,\n",
    "    \"created_at_ts\": np.uint64,\n",
    "    \"publisher_id\": np.uint8,\n",
    "    \"words_count\": np.uint16\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On convertit les timestamps en datetime\n",
    "articles_metadata[\"created_at_ts\"] = pd.to_datetime(articles_metadata['created_at_ts'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa29411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme les colonnes\n",
    "articles_metadata = articles_metadata.rename(columns={\n",
    "    \"created_at_ts\": \"created_dt\",\n",
    "    \"words_count\": \"word_nb\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828fc6c",
   "metadata": {},
   "source": [
    "### Indicateurs statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ae6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\"word_nb\", \"created_dt\"]\n",
    "cat_vars = [\"article_id\", \"category_id\", \"publisher_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47209b",
   "metadata": {},
   "source": [
    "#### Variables de type numérique\n",
    "\n",
    "Voici le tableau des indicateurs statistiques des variables de type numérique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_metadata[num_vars].describe(\n",
    "    percentiles=[0.25, 0.5, 0.70, 0.95, 0.99],\n",
    "    datetime_is_numeric=True\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789c00b",
   "metadata": {},
   "source": [
    "En moyenne, les articles sont composés de 191 mots. Il s'agit donc d'articles très courts.\n",
    "\n",
    "70% ont été créés avant le 13/10/2017 et ont donc potentiellement été visibles par les utilisateurs de notre jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a7dff",
   "metadata": {},
   "source": [
    "#### Variables de type catégorie\n",
    "\n",
    "Voici le tableau des indicateurs statistiques des variables de type catégorie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ef275",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_metadata[cat_vars].astype(\"category\").describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2c079",
   "metadata": {},
   "source": [
    "Il y a 461 catégories d'articles différentes.\n",
    "\n",
    "`publisher_id` ne contient qu'une seule valeur, on pourra donc supprimer cette variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e191da",
   "metadata": {},
   "source": [
    "### Suppression des variables inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les colonnes inutiles\n",
    "articles_metadata = articles_metadata.drop(columns=[\"publisher_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf0bcb",
   "metadata": {},
   "source": [
    "### Distribution du nombre d'articles par catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ae373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par catégorie\n",
    "grp = articles_metadata.groupby(\"category_id\")\n",
    "\n",
    "# On agrège les données\n",
    "grp_agg = grp.agg({\"article_id\": \"count\"})\n",
    "grp_agg = grp_agg.rename(columns={\"article_id\": \"article_nb\"})\n",
    "\n",
    "# On calcule le ratio du nombre d'articles\n",
    "grp_agg[\"ratio\"] = grp_agg[\"article_nb\"] / grp_agg[\"article_nb\"].sum()\n",
    "\n",
    "# On affiche les indicateurs statistiques\n",
    "grp_agg.describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c2ab4",
   "metadata": {},
   "source": [
    "Plus de 50% des catégories ont au moins 36 articles et plus de 25% ont au moins 520 articles.\n",
    "\n",
    "Une des catégorie contient 12.817 articles, soit 3.5% du total des articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843092de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On trie par nombre d'articles\n",
    "grp_agg = grp_agg.sort_values(\"article_nb\", ascending=False)\n",
    "\n",
    "# On prend les catégories les plus représentées\n",
    "most_frequents = grp_agg.iloc[:50]\n",
    "\n",
    "# On regroupe les autres\n",
    "others = grp_agg.iloc[50:].sum().to_frame().T\n",
    "others.index = [\"others\"]\n",
    "\n",
    "# On concatène les données\n",
    "grp_agg = pd.concat([most_frequents, others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "most_frequents[[\"article_nb\"]].plot.bar(ax=ax)\n",
    "\n",
    "ax.set_title(\"Répartition du nombre d'articles des 50 catégories les plus représentées\")\n",
    "ax.set_xlabel(\"Catégorie\")\n",
    "ax.set_ylabel(\"Nombre d'articles\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7017526",
   "metadata": {},
   "source": [
    "On constate que les articles sont bien répartis dans de nombreuses catégories. Il pourrait s'agir d'une feature intéressante pour les modèles de type content based."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de3597",
   "metadata": {},
   "source": [
    "### Nombre d'articles ajoutés par an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regroupe les données par année\n",
    "grp = articles_metadata.groupby(pd.Grouper(key=\"created_dt\", freq=\"Y\"))\n",
    "\n",
    "# On calcule le nombre d'articles ajoutés\n",
    "grp_agg = grp.agg({\"article_id\": \"count\"})\n",
    "\n",
    "# On calcule le ratio du nombre d'articles\n",
    "grp_agg[\"ratio\"] = grp_agg[\"article_id\"] / grp_agg[\"article_id\"].sum()\n",
    "\n",
    "# On nettoie les colonnes et l'index pour l'affichage\n",
    "grp_agg = grp_agg.rename(columns={\n",
    "    \"article_id\": \"nombre d'articles ajoutés dans l'année\"\n",
    "})\n",
    "grp_agg.index = grp_agg.index.year\n",
    "grp_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db06916",
   "metadata": {},
   "source": [
    "43% des articles ont été ajouté en 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "grp_agg[[\"nombre d'articles ajoutés dans l'année\"]].plot.bar(ax=ax)\n",
    "\n",
    "ax.set_title(\"Nombre d'articles ajoutés par an\")\n",
    "ax.set_xlabel(\"Année\")\n",
    "ax.set_ylabel(\"Nombre d'articles\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nettoie les ressources\n",
    "del(articles_metadata)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df795106",
   "metadata": {},
   "source": [
    "## Fichier articles_embeddings.pickle\n",
    "\n",
    "Les contenus des articles ont été transformés en embeddings par le block ACR (Article Content Representation) d'un model de recommandation nommé CHAMELEON ([en savoir plus](https://arxiv.org/abs/1904.10367)). Cette représentation numérique dans un espace à dimensions réduites va nous premettre de calculer des score de similarité entre les articles. Ces scores sont notamment utilisés par les modèles de type content based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les embeddings des articles\n",
    "with open(PICKLE_PATH + \"articles_embeddings.pickle\", \"rb\") as f:\n",
    "    articles_embeddings = pickle.load(f)\n",
    "    \n",
    "# On les place dans un dataframe\n",
    "articles_embeddings = pd.DataFrame(\n",
    "    articles_embeddings.tolist(),\n",
    "    columns=[f\"emb_{i}\" for i in range(articles_embeddings.shape[1])]\n",
    ")\n",
    "articles_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc826f",
   "metadata": {},
   "source": [
    "Les articles sont représentés par des embeddings de dimension 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cf994",
   "metadata": {},
   "source": [
    "### Indicateurs statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_embeddings.iloc[:10].T.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b48a6d",
   "metadata": {},
   "source": [
    "En observant les indicateurs statistiques des embeddings des 10 premiers articles, on s'apperçoit que les embeddings ont des valeurs comprises entre -1 et 1, qu'ils sont centrés en 0 et ont un écart type de 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41320a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nettoie les ressources\n",
    "del(articles_embeddings)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ea4b1",
   "metadata": {},
   "source": [
    "# Enregistrement des données dans le feature store\n",
    "\n",
    "A terme, nous souhaiterions obtenir l'architecture suivante pour la collecte des données :\n",
    "\n",
    "<img src=\"./data/img/archi_data_collect.png\" alt=\"Acquisition des données\" style=\"width:600px;\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Acquisition des données</p>\n",
    "\n",
    "Nous y retrouvons les blocs suivantes :\n",
    "- `Mobile app` :\n",
    "\t- L’utilisateur interagit avec l’application (par exemple : clique sur un article).\n",
    "\t- L’application envoie ces informations au backend.\n",
    "\t- Permet l’ajout de nouveaux utilisateurs via un formulaire d'inscription (non implémenté).\n",
    "\n",
    "- `Dashboard` (non implémenté) :\n",
    "\t- Permet l’ajout de nouveaux articles via un formulaire d'inscription.\n",
    "\n",
    "- `App backend` (non implémenté) :\n",
    "\t- Enregistre les évènements de l’application mobile dans des logs (comme les fichiers clicks_hour_xxx.csv).\n",
    "\t- Permet l’ajout de nouveaux utilisateurs.\n",
    "\t- Permet l’ajout de nouveaux articles.\n",
    "\n",
    "- `ETL` (non implémenté) :\n",
    "\t- Azure function qui s’exécute par exemple 1 fois par jour.\n",
    "\t- Extract, Transform and Load des données du backend vers le feature store (création des embeddings etc...).\n",
    "\n",
    "- `Feature store`:\n",
    "    - Azure Blob Datastore pour l'enregistrement des fichiers.\n",
    "    - Azure Dataset pour regrouper les fichiers enregistrés et les rendre disponibles pour la transformation des données.\n",
    "\t- Enregistrement des features qui seront utilisés par les modèles de recommandation en développement et en production.\n",
    "    \n",
    "Les blocs en gris ne sont pas encore implémentés. Nous allons donc manuellement enregistrer notre jeu de données dans le feature store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d6cde",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "On commence par charger le contenu des fichiers `clicks_hour_xxx.csv` dans un DataFrame via la fonction `get_clicks`. Cette fonction va automatiquement réaliser toutes les étapes de nettoyage que l'on a effectué durant l'exploration et l'analyse des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d069e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les données\n",
    "clicks = get_clicks(CSV_PATH + \"clicks\")\n",
    "\n",
    "# On supprime les jours qui ont trop peu de cliques (vu dans l'EDA)\n",
    "clicks = clicks[clicks[\"click_dt\"] < datetime(2017, 10, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2030353",
   "metadata": {},
   "source": [
    "De même, on fait appel à la fonction `get_articles` qui va charger les metadatas des articles, les nettoyer et les concaténer avec les embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = get_articles(\n",
    "    CSV_PATH + \"articles_metadata.csv\",\n",
    "    PICKLE_PATH + \"articles_embeddings.pickle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc61c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0aad0d",
   "metadata": {},
   "source": [
    "## Enregistrement dans le datastore\n",
    "\n",
    "On enregistre les données des cliques dans des fichiers séparés en les regroupant jour par jour.\n",
    "\n",
    "On remarquera, en observant les logs ci-dessous, que l'on a créé un arborescence de type `<année>/<mois>/<jour>`. En effet, Azure propose une fonctionnalité qui permettra par la suite de rechercher et de filtrer les données des Datasets en prenant en compte cette arborescence ([en savoir plus](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#from-parquet-files-path--validate-true--include-path-false--set-column-types-none--partition-format-none-)). Dans la pratique, cette fonctionnalité semble ralentir le chargement des Datasets.\n",
    "\n",
    "Nous avons finalement choisi une autre fonctionnalité proposé par Azure et qui permet de filter des données des Datasets en se basant sur une variable de type horodatage présente dans les fichiers ([en savoir plus](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py#with-timestamp-columns-timestamp-none--partition-timestamp-none--validate-false----kwargs-))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les données jour par jour dans le datastore\n",
    "upload_clicks_in_datastore(clicks, datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614d6a2",
   "metadata": {},
   "source": [
    "On enregistre ensuite les données des articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e2aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les données année par année dans le datastore\n",
    "upload_articles_in_datastore(articles, datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9a8ee",
   "metadata": {},
   "source": [
    "## Enregistrement des datasets\n",
    "\n",
    "Un Dataset Azure est une abstraction qui nous permet de créer un jeu de données en regroupant de manière symbolique des fichiers du Datastore. Ainsi, on pourra continuer d'ajouter des données de cliques sous forme de fichiers dans le Datastore et il nous suffira juste de mettre à jour le Dataset correspondant. De plus, chaque mise à jour d'un Dataset est versionnée, on conservera ainsi l'historique de l'évolution des Datasets.\n",
    "\n",
    "La fonction suivante va regouper tous les fichiers des données de cliques disponibles sur le Datastore et va créer/updater le Dataset `clicks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée/update le dataset avec tous les fichiers clicks présents dans le datastore\n",
    "clicks_ds = create_update_clicks_dataset(ws, datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13727fbf",
   "metadata": {},
   "source": [
    "La fonction suivante va regouper tous les fichiers des données des articles disponibles sur le Datastore et va créer/updater le Dataset `articles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée/update le dataset avec tous les fichiers articles présents dans le datastore\n",
    "articles_ds = create_update_articles_dataset(ws, datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751dfcc4",
   "metadata": {},
   "source": [
    "# Pipeline de transformation des données\n",
    "\n",
    "Nous allons devoir transformer nos données afin qu'elles soient utilisables par nos modèles. Cette section représente les blocs `Data extraction` et `Data transform` de notre architecture. On utilisera les mêmes scripts durant l'expérimentation des modèles que durant le déploiement du modèle final en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07da135",
   "metadata": {},
   "source": [
    "## Extraction des données\n",
    "\n",
    "La première étape du pipeline consiste à extraire les données du feature store et de les spliter en 1 jeu d'entrainement, 1 jeu de validation et 1 jeu de test.\n",
    "\n",
    "Le paramètre `test_end_dt` correspond à l'horodatage maximal qui sera présent dans le jeu de test.\n",
    "`test_day_nb` représente le nombre de jour que l'on prendra dans le jeu de test.\n",
    "On mettra ensuite les `valid_day_nb` jours précédents dans le jeu de validation.\n",
    "Enfin, on prendra les `train_day_nb` jours précédents dans le jeu d'entrainement.\n",
    "\n",
    "Nous allons donc spliter nos données de manière chronologique. Cela évitera d'entrainer notre modèle avec des données qu'il n'est pas censé voir, ce qui pourrait fausser son évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db92650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée l'étape d'extraction des données du feature store\n",
    "(\n",
    "    data_extraction_step,\n",
    "    test_clicks_path,\n",
    "    valid_clicks_path,\n",
    "    train_clicks_path,\n",
    "    articles_path\n",
    ") = get_data_extraction_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    test_end_dt=datetime(2017, 10, 17),\n",
    "    test_day_nb=1,\n",
    "    valid_day_nb=1,\n",
    "    train_day_nb=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efecc7",
   "metadata": {},
   "source": [
    "## Transformation des données\n",
    "\n",
    "Nous allons effectuer du feature engineering afin d'adapter nos données aux besoin de nos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9973912",
   "metadata": {},
   "source": [
    "### Création des notation des articles\n",
    "\n",
    "Les modèles de collaborative filtering ont besoin de notes représentant les affinités que les utilisateurs ont pour les articles.\n",
    "\n",
    "Nous n'avons pas de note explicite dans notre jeu de données. Nous allons donc devoir créer des notes inplicites, déduite à partir du nombre de clicks sur chaque article. Nous allons créer 2 notes différentes qui seront testées durant la recherche des hyperparamètres :\n",
    "- `rating_click_nb` : Nombre total de clicks par un utilisateur sur un article.\n",
    "- `rating_click_per_session_ratio` : `rating_click_nb` normalisé par le nombre total de clicks dans la session de l'utilisateur.\n",
    "\n",
    "Le jeu de données original ne contient pas non plus de vrais négatif (par exemple : des articles qui ont été vus par l'utilisateur mais sur lesquels il n'a pas cliqué). Nous allons donc ajouter des vrais négatifs en prenant au hasard des articles du jeu de données `clicks_path` et qui n'ont jamais été cliqués par l’utilisateur. Le paramètre `tn_nb` permet de spécifier le nombre de vrais négatif à sélectionner pour chaque utilisateur. Si ce paramètre vaut `None`, la fonction calcule `tn_nb` afin de créer un jeu de données équilibré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fab1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée les étapes de notation des articles pour chacun des jeux de données\n",
    "test_user_article_ratings_step = get_user_article_ratings_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    clicks_path=test_clicks_path,\n",
    "    tn_nb=100,\n",
    "    dataset_name=\"test_user_article_ratings\"\n",
    ")\n",
    "\n",
    "valid_user_article_ratings_step = get_user_article_ratings_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    clicks_path=valid_clicks_path,\n",
    "    tn_nb=100,\n",
    "    dataset_name=\"valid_user_article_ratings\"\n",
    ")\n",
    "\n",
    "train_user_article_ratings_step = get_user_article_ratings_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    clicks_path=train_clicks_path,\n",
    "    tn_nb=None,\n",
    "    dataset_name=\"train_user_article_ratings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0af3c7",
   "metadata": {},
   "source": [
    "### Création des profils des articles\n",
    "\n",
    "Pour chaque article, nous allons créer un profil qui va permettre de la caractériser. Nous allons principalement reprendre les données du Dataset `articles`. Nous allons aussi créer des features par agrégation de données (nombre total de clicks etc…).\n",
    "\n",
    "Ces données seront principalement utilisées par les modèles de type content based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée l'étape de création des profils des articles\n",
    "article_profiles_step, article_profiles_path = get_article_profiles_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    clicks_path=train_clicks_path,\n",
    "    articles_path=articles_path,\n",
    "    dataset_name=\"article_profiles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779846df",
   "metadata": {},
   "source": [
    "### Création des profils des utilisateurs\n",
    "\n",
    "Comme précédemment, nous allons créer un profil par utilisateur. Nous pourrons y ajouter des données spécifiques aux utilisateurs qui vont permettre de rechercher les utilisateurs similaires. Nous allons aussi agréger les données des articles cliqués par l'utilisateur afin de créer le profil d'article moyen de l'utilisateur. On pourra alors utiliser ces données dans un modèle de type content based pour trouver des articles similaires à proposer à l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cfc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée l'étape de création des profils des utilisateurs\n",
    "train_user_profiles_step = get_user_profiles_step(\n",
    "    ws,\n",
    "    SCRIPTS_PATH + \"data_transform\",\n",
    "    clicks_path=train_clicks_path,\n",
    "    article_profiles_path=article_profiles_path,\n",
    "    dataset_name=\"train_user_profiles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47663369",
   "metadata": {},
   "source": [
    "### Exécution du pipeline\n",
    "\n",
    "On peut maintenant lancer l'exécution du pipeline complet sur des clusters de calcul. On pourra aussi lancer ce même pipeline via le workflow [Transform data](https://github.com/Sako74/p9-demo/actions/workflows/data_transform.yml) des Github actions.\n",
    "\n",
    "<img src=\"./data/img/data_transform.png\" alt=\"Pipeline de transformation des données\" style=\"width:900px;\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Pipeline de transformation des données</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On soummet l'exécution du pipeline\n",
    "run = exp_submit(\n",
    "    ws,\n",
    "    steps=[\n",
    "        data_extraction_step,\n",
    "        test_user_article_ratings_step,\n",
    "        valid_user_article_ratings_step,\n",
    "        train_user_article_ratings_step,\n",
    "        article_profiles_step,\n",
    "        train_user_profiles_step\n",
    "    ],\n",
    "    regenerate_outputs=False,\n",
    "    wait_for_completion=False,\n",
    "    show_output=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be91b7",
   "metadata": {},
   "source": [
    "# Vérification des données\n",
    "\n",
    "Nous allons charger les Datasets précédemment générés comme le ferait un script d'entrainement de modèle.\n",
    "\n",
    "Nous n'allons ici que visualiser des échantillons de données afin de vérifier s'il n'y a pas d'erreur flagrante. A terme, il serait intéressant de vérifier l'intégrité des données automatiquement. Cette étape correspondrait aux blocs `Data verification` de notre architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e73ba6",
   "metadata": {},
   "source": [
    "## Chargement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b934c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les datasets\n",
    "test_user_article_ratings_ds = Dataset.get_by_name(ws, \"test_user_article_ratings\")\n",
    "valid_user_article_ratings_ds = Dataset.get_by_name(ws, \"valid_user_article_ratings\")\n",
    "train_user_article_ratings_ds = Dataset.get_by_name(ws, \"train_user_article_ratings\")\n",
    "\n",
    "article_profiles_ds = Dataset.get_by_name(ws, \"article_profiles\")\n",
    "train_user_profiles_ds = Dataset.get_by_name(ws, \"train_user_profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14615a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les datasets dans des DataFrames\n",
    "test_user_article_ratings = test_user_article_ratings_ds.to_pandas_dataframe()\n",
    "valid_user_article_ratings = valid_user_article_ratings_ds.to_pandas_dataframe()\n",
    "train_user_article_ratings = train_user_article_ratings_ds.to_pandas_dataframe()\n",
    "\n",
    "article_profiles = article_profiles_ds.to_pandas_dataframe()\n",
    "train_user_profiles = train_user_profiles_ds.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126125c",
   "metadata": {},
   "source": [
    "## Notation des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c020cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_article_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea768479",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_article_ratings.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a863f9",
   "metadata": {},
   "source": [
    "Les données des notations des articles du jeu de test semblent cohérentes. Les valeurs `ERROR` correspondent aux horodatages inconnus de vrais négatifs que l'on a ajouté. Cela n'affectera pas l'entrainement des modèles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_article_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2389239",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_article_ratings.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb996f",
   "metadata": {},
   "source": [
    "Les données des notations des articles du jeu de validation semblent cohérentes. Les valeurs `ERROR` correspondent aux horodatages inconnus de vrais négatifs que l'on a ajouté. Cela n'affectera pas l'entrainement des modèles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb1865",
   "metadata": {},
   "source": [
    "Les données semblent cohérentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d751e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68af614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article_ratings.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d4319",
   "metadata": {},
   "source": [
    "Les données des notations des articles du jeu d'entrainement semblent cohérentes. Les valeurs `ERROR` correspondent aux horodatages inconnus de vrais négatifs que l'on a ajouté. Cela n'affectera pas l'entrainement des modèles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94acae2",
   "metadata": {},
   "source": [
    "## Profils des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_profiles.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf5b2c",
   "metadata": {},
   "source": [
    "Les données des profils des articles semblent cohérentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be28b5",
   "metadata": {},
   "source": [
    "## Profils des utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccadead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_profiles.iloc[[0, 1, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f8139",
   "metadata": {},
   "source": [
    "Les données des profils des utilisateurs semblent cohérentes."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "p9"
  },
  "kernelspec": {
   "display_name": "p9",
   "language": "python",
   "name": "p9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sommaire",
   "title_sidebar": "Sommaire",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
